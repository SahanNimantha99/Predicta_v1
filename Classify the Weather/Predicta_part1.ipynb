{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77mRxzlwKdBQ",
        "outputId": "5a514413-b8da-4aec-8794-e138b243b47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  city_id        date  avg_temp_c  min_temp_c  max_temp_c  precipitation_mm  \\\n",
            "0    C001  2014-01-01         6.6        -1.4        11.6               NaN   \n",
            "1    C001  2014-01-02         9.3         6.3        13.3               NaN   \n",
            "2    C001  2014-01-03         7.6         1.9        14.0               NaN   \n",
            "3    C001  2014-01-04         7.6         3.9        13.3               NaN   \n",
            "4    C001  2014-01-05         8.6         0.5        16.9               NaN   \n",
            "\n",
            "   snow_depth_mm  avg_wind_dir_deg  avg_wind_speed_kmh  \n",
            "0            NaN             168.0                 6.2  \n",
            "1            NaN             155.0                10.0  \n",
            "2            NaN               NaN                 5.8  \n",
            "3            NaN             291.0                11.3  \n",
            "4            NaN               NaN                 5.0  \n",
            "   submission_ID  avg_temp_c\n",
            "0              1         NaN\n",
            "1              2         NaN\n",
            "2              3         NaN\n",
            "3              4         NaN\n",
            "4              5         NaN\n",
            "   submission_ID city_id        date\n",
            "0              1    C001  2019-01-01\n",
            "1              2    C001  2019-01-02\n",
            "2              3    C001  2019-01-03\n",
            "3              4    C001  2019-01-04\n",
            "4              5    C001  2019-01-05\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016318 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2066\n",
            "[LightGBM] [Info] Number of data points in the train set: 145846, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 19.201698\n",
            "Validation RMSE: 0.8888711777278354\n",
            "0    0.823480\n",
            "1    0.857019\n",
            "2    0.830402\n",
            "3    0.801355\n",
            "4    0.792416\n",
            "Name: avg_temp_c, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "historical_weather = pd.read_csv('/historical_weather.csv')\n",
        "sample_submission = pd.read_csv('/sample_submission.csv')\n",
        "submission_key = pd.read_csv('/submission_key.csv')\n",
        "\n",
        "# Display the first few rows to understand the structure\n",
        "print(historical_weather.head())\n",
        "print(sample_submission.head())\n",
        "print(submission_key.head())\n",
        "\n",
        "# Handle missing values\n",
        "historical_weather.fillna(method='ffill', inplace=True)\n",
        "historical_weather.fillna(method='bfill', inplace=True)\n",
        "\n",
        "# Convert `date` to datetime\n",
        "historical_weather['date'] = pd.to_datetime(historical_weather['date'])\n",
        "\n",
        "# Create time-based features\n",
        "historical_weather['year'] = historical_weather['date'].dt.year\n",
        "historical_weather['month'] = historical_weather['date'].dt.month\n",
        "historical_weather['day'] = historical_weather['date'].dt.day\n",
        "historical_weather['day_of_week'] = historical_weather['date'].dt.dayofweek\n",
        "\n",
        "# Create lag and rolling window features\n",
        "historical_weather['lag_1'] = historical_weather.groupby('city_id')['avg_temp_c'].shift(1)\n",
        "historical_weather['rolling_mean_7'] = historical_weather.groupby('city_id')['avg_temp_c'].rolling(window=7).mean().reset_index(0, drop=True)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data = historical_weather[historical_weather['date'] < '2018-01-01']\n",
        "val_data = historical_weather[historical_weather['date'] >= '2018-01-01']\n",
        "\n",
        "# Define features and target\n",
        "features = ['month', 'day', 'day_of_week', 'lag_1', 'rolling_mean_7', 'min_temp_c', 'max_temp_c', 'precipitation_mm', 'snow_depth_mm', 'avg_wind_dir_deg', 'avg_wind_speed_kmh']\n",
        "X_train = train_data[features]\n",
        "y_train = train_data['avg_temp_c']\n",
        "X_val = val_data[features]\n",
        "y_val = val_data['avg_temp_c']\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create the LightGBM dataset\n",
        "train_set = lgb.Dataset(X_train, label=y_train)\n",
        "val_set = lgb.Dataset(X_val, label=y_val, reference=train_set)\n",
        "\n",
        "# Define parameters\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model = lgb.train(params, train_set, num_boost_round=1000, valid_sets=[train_set, val_set])\n",
        "\n",
        "# Validate the model\n",
        "y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
        "print(f'Validation RMSE: {rmse}')\n",
        "\n",
        "# Prepare submission data\n",
        "# Convert 'date' in submission_key to datetime\n",
        "submission_key['date'] = pd.to_datetime(submission_key['date'])\n",
        "\n",
        "# Now perform the merge\n",
        "submission_data = pd.merge(submission_key, historical_weather, on=['city_id', 'date'], how='left')\n",
        "submission_data.fillna(method='ffill', inplace=True)\n",
        "submission_data.fillna(method='bfill', inplace=True)\n",
        "\n",
        "submission_data['month'] = submission_data['date'].dt.month\n",
        "submission_data['day'] = submission_data['date'].dt.day\n",
        "submission_data['day_of_week'] = submission_data['date'].dt.dayofweek\n",
        "\n",
        "submission_data['avg_temp_c'] = model.predict(submission_data[features], num_iteration=model.best_iteration)\n",
        "\n",
        "print(submission_data['avg_temp_c'].head())\n",
        "# Prepare final submission file\n",
        "final_submission = submission_data[['submission_ID', 'avg_temp_c']]\n",
        "final_submission.to_csv('/my_submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KH_a7iKI7EU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}